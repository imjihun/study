
* IPC(Inter Process Communication)

IPC 를 사용하는 이유는 무엇인가 ?
A 프로세스와 B 프로세스가 각각 존재한다 가정했을 때
A 와 B 가 서로가 가지고 있는 정보를
공유할 수 없기 때문이다.

우선 프로세스의 기본적인 개념을 생각해보면
프로세스는 각자 자기 자신만의
고유한 4 GB 가상 메모리 공간을 가지고 있다.
이 상태에서 서로 독립적인 공간을 가지고 있다보니
정보를 공유할 수 없었다
(저번에 간략한 포인터 예를 통해서도 확인 했었다)

그러나 IPC 를 사용하면 Pipe 나,
Semaphore, Message Queue, Shared Memory 등은
프로세스 간에 정보를 공유할 수 있도록 만들어준다.

원리는 메모리 상에 특정한 공간을 잡아놓고
해당 공간에 접근할 수 있는 권한을 만든다.
그리고 그 공간에 서로
공유하고자 하는 정보를 집어넣는 것이다.
그러면 권한을 가지고 있는 녀석들끼리
메모리에 접근해서 값을
읽거나 쓰는 작업을 수행할 수 있을 것이다.

문제는 Semaphore 는
단순히 이러한 용도로 개발된 것이 아니라는 것이다.
Semaphore 가 나오게 되면 System 에서는 반드시
같이 따라서 나오게 되는 것이 Spinlock 이며
또한 Critical Section 이라는 영역이 같이 나온다.

여러 개의 프로세스가 동시 다발적으로 구동된다고 할 때
특정한 메모리에 여러 프로세스가 동시에 접근해서
값을 읽거나 쓴다고 생각해보자!

그러면 분명히 값을 제대로 읽지 못한 프로세스
혹은 값을 제대로 쓰지 못한 프로세스 등
다양한 문제가 발생하게 될 것이다.

이렇게 여러 프로세스들이 하나의 공간에 접근해서
데이터의 쓰기 및 읽기 등이
꼬이게 될 가능성이 있는 공간을
Critical Section 이라 한다.

참고로 위에 적어놓은 원리는 Message Queue 에만 국한됨
Semaphore 관점에서는 공유하게 되는 공간이
위의 원리와 같은 공간일 수도 있고
전역 변수와 같은 정보를 공유하는 Thread 일 수도 있음
중요한것은 어쨋든 정보가 공유가 가능할 경우
읽기 및 쓰기가 꼬여 문제가 발생할 수 있는
그 영역 자체를 Critical Section 이라 한다는 것임

그렇다면 도대체 왜 ? 값이 꼬일까 ?
자세한것은 그림을 그려야 하니 조금 후에 할 것인데
우선 이론적으로 파악을 해보자면
A 프로세스에서 + 연산을 하고 있는 도중에
Context Switching 이 발생하는 것이다.
그래서 B 로 제어권이 넘어갔다고 하자!
B 는 - 연산을 하고 있는 것이다.
예로 현재 공유 정보가 1이였다고 해보자!
A - B - A - B 를 진행했다면 값은 1로 유지되야 한다.

그러나 Critical Section 문제가 터지게 되면
A 가 연산 도중에 B 로가서 연산이 완료되고
A 가 다시 연산하면 0이 될 것이며
다시 위와 같은 상황이 반복되면 -1 이 될 것이다.
즉, 원하는 결과인 1 아닌 -1 이 되버리는 것이다.
이런 상황을 막기 위해 등장한 개념이
바로 Semaphore 이다.


Spinlock

이 녀석은 Polling 메커니즘을 따르는 Lock 메커니즘이다.
기본적으로 시스템 프로그래밍을 하게되면
나오는 구도가 아래와 같다.

Semaphore(Mutex) vs Spinlock

위와 같은 구도로 나오는데 Spinlock 은 도대체 뭘까 ?
여기서도 굉장히 흥미로운 주제가 기다리고 있다.

아무튼 Semaphore 와 Spinlock 은 누가 더 좋을까 ?
경우에 따라서 둘 다 좋다!

Semaphore 의 경우 Semaphore 에 속해
구동하게 되는 작업이 방대할 경우
굉장한 이득을 얻을 수 있다.

반면 Spinlock 의 경우 작업의 양이
비교적 간단하면 간단할 수록 굉장한 이득을 얻게 된다.

Semaphore 나 Spinlock 모두 이러한 특징이
나타나게 되는 원인은 결국 Context Switching 이다.



* 공유 메모리(IPC) 컴파일 및 실행 방법

gcc -o send send.c shmlib.c
gcc -o recv recv.c shmlib.c

터미널을 2개 띄우도록 한다.
그리고 한 쪽에서 아래와 같이 !

./send

다른 한쪽에서 아래와 같이 !

./recv

그리고 ./send 를 실행시킨쪽에서 앤터키 한 번 입력
이후에 ./recv 를 실행시킨쪽에서 앤터키 한 번 입력

그러면 send 쪽의 정보가 recv 에 공유될 것이다.





* OpenMPI(슈퍼컴퓨팅 라이브러리) 설치 방법

wget https://www.open-mpi.org/software/ompi/v2.0/downloads/openmpi-2.0.0.tar.gz

tar zxvf openmpi-2.0.0.tar.gz

cd openmpi-2.0.0

./configure --prefix=/opt/openmpi

make all

sudo make install

sudo vi /etc/profile.d/openmpi.sh

OPENMPI_PATH=/opt/openmpi
MPI_HOME=${OPENMPI_PATH}
if ! echo ${PATH} | /bin/grep -q ${OPENMPI_PATH}/bin; then
          PATH=${OPENMPI_PATH}/bin:${PATH}
fi



source /etc/profile.d/openmpi.sh



sudo vi /etc/ld.so.conf.d/openmpi.conf
 
/opt/openmpi/lib



sudo ldconfig



mpicc mpi_hello.c -o mpi_hello
mpirun -np 4 mpi_hello















