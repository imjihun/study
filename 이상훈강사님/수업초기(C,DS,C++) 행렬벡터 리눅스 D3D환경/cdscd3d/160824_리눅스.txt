xxd 메모리별로 텍스트파일 출력

man dup
man open
man write
man read
혹시나 안나온다.아래식으로
man -s1 read <- 리눅스 터미널 명령어 read의 설명
man -s3 read <- System Call 함수의 설명(-s2도)


dup(fd) <-파일 디스크립터 복사본을 만듭니다. 원본 디스크립터와 복사된 디스크립터의 읽기/쓰기 포인터는 공유됩니다. 즉, 원본과 복사본 디스크립터마다 따로 읽기/쓰기 포인터가 존재하지 않습니다.
return ->복사된 파일 디스크립터 번호로 사용되지 않은 가장 작은 번호가 자동으로 지정되어 반환됩니다.
함수 실행이 실패되면 -1 이 반환됩니다.

dup(fd) 가장최근에 닫은 파일디스크립터를 fd가 대체하게 해준다.
//////////-> 파일차원에서의 redirection리다이렉션




ps -ef

pid = task를 사람으로 봤을때 주민등록번호
ppid =부모pid는 같을수도 있다.
ps -ef | grep bash 리눅스터미널에서 '|'은 Pipe를 대체한다
ps -ef | grep bash | grep -v grep -> bash프로세스 1개
ps -ef 결과 -> grep bash 결과가 출력

마우스 우클릭->open terminal

ps -ef | grep bash | grep -v grep -> bash프로세스 여러개
열려진 terminal개수가 bash프로세스의 개수가 된다.
/////////-> 프로세스차원에서의 리다이렉션
//////////dup로는 프로세스차원의 리다이렉션을 못한다.




IPC = Inter Process Communication 의 일종인 Pipe통신

IPC에는 Message Queue, Shared Memory,
Pipe, Semaphore, Spinlock등이 존재함

***또 Semaphore vs Spinlock은 회사들의 대표 면접문제!!



파일간의 정보교환
	리다이렉션(dup)

A프로세스와 B프로세스간의 정보를 파일간의 정보교환으로는 리다이렉션을 못한다!!!(정보교환이 안됨)
-> 프로세스간 통신 -> IPC 메커니즘 (그중하나가 Pipe)

IPC 메커니즘 안에 네트워크가 들어있다.

원격 프로세스간 통신이 네트워크이다.





$ pipe.t
$ touch pipe.c
$ mkfifo myfifo
다른 터미널창
cat > myfifo



Blocking vs Non-Blocking
CPU자원을 잡고 있느냐 마느냐에 대한 차이!
Blocking을 하면 특정 조건을 만족할 때까지 Resource활용 불가
Non-Blocking은 상관없이 준비되면 실행 아니면 대기
Blocking	->전화->순서가 중요한 작업
Non-Blocking	->카톡->효율적임

read(0,buf,sizeof(buf)) <- Blocking함수라서 끝나기 전까지 다음거 실행 불가

///////프로세스, 쓰레드 -> task_struct 매칭

./a.out -> 실행->메모리에 로드하겠다.->task구조체생성(aaa)
cat > myfifo -> 실행->task구조체생성(bbb)
context switching 메커니즘->프로세스 교체지 레지스터 보관
할일이 끝나면 자동으로 context switching
주어진 시간이 끝나도 context switching

polling		속도느림
interrupt	속도빠름




/////////////////////////용어정리
1. Context Switching(컨텍스트 스위칭)
A프로세스(프로그램A) 와 B프로세스(프로그램B)가 있다고 가정한다.
 A가 수행하는 작업은 아래와 같다고 가정하도록 하자
  num1 =3;
  num2 =7;
  num3 = num1 + num2;

 B가 수행하는 작업은 아래와 같다고 가정한다.
  num1 =10;
  num2 =33;
  num3 = num1 + num2;

 이상황에서 생각해야 하는 것들이 몇가지 있다.

  1)CPU가 1개라면 오로지 한 순간에 한가지 동작만을 수행한다는 것.
  2)프로세스들에게 정해진 Time Slice(시간조각)이 있다는 것
    즉, 이 시간의 조각을 모두 소진하면 자동으로 Context Switching 하게 됨.

 위의 2가지 개념을 파악한 이후 내용을 진행하면 되겠다.
 우선 A에서 num1 = 3;이라는 부분만을 진행했다고 가정한다.
 이때 A에게 주어진 Time Slice가 모두 소진 되어
 제어권이 B로 넘어갔다고 가정한다.
 (제어권이 넘어갈때 Context Switching이 발생함)

그러면 B는 num1=10;을 수행하고, 이 녀석도 재수없게 이 시점에 Time Slice가 만료되었다.
그러면 역시 Context Switching이 발생하여 제어권이 A로 넘어가게 될 것이다.
A에 도착하면 앞서서 num1은 수행을 했기 때문에 num2=7;을 수행할 것이다.
그리고 num3 = num1 + num2를 수행할텐데 앞서서 B에서 num1의 값을 3이 아닌 10으로 바꿔놨다.
정상적인 연산 결과라면 num1=3과 num2=7의 합으로 10이 나와야 하는데 
현재 num1=10이므로 num2=7과 합을 구하게 되면 17이 계산된다.

이것은 우리가 원치 않았던 결과이다.
원했던 결과는 10인데 연산 결과는 17이 되어버렸으니까 말이다.

그리고 앞서서 우리가 기계어를 공부하면서 살펴보았던 레지스터를 생각해보자
기계 입장에서는 변수 또안 메모리 혹은 레지스터에 값을 넣어 취급했었다.
또 연산을 할 때를 생각해보면 레지스터들을 굉장히 많이 활용했다.
(산술 연산에 사용되는 레지스터는 뭐다? eax)

이 뜻은 결국 실제 우리가 연산하기 위해 필요로 하는 정보들이 레지스터에 들어감을 의미한다.
그러므로 레지스터의 정보를 어딘가에 저장해두고 이를 필요에 따라서 복원할 수 있다면
우리가 원했던 결과 10을 정확하게 얻어낼 수 있을 것이다.
(이것이 어제 task_struct 구조체에서 살펴봤던 thread_struct 구조체다)

자! 그럼 이제 이렇게 정보를 저장할 수 있는 공간이 있다고 생각해보자!
그리고 다시 위의 예를 구동시켜보자

마찬가지로 아까와 같이 A프로세스에서 num1=3; 을 수행하고 Context Switching을 발생시켜서 제어권을 B로 넘긴다
이때 아까와는 다르게 현재 A프로세스의 레지스터 정보들을 thread_struct 구조체에 저장한다.
(여기서 잘 생각해야 하는것이 있는데 수업할 때 구동되는 프로그램들마다 무엇이 생긴다? task_struct,
즉 프로세스는 전부다 task_struct란 뜻
나중에 보게 되겠지만 쓰레드라는 것도 task_struct임)

그리고 이제 B에서 num1 = 10;을 수행하고 앞선 예와 마찬가지로 Context Switching을 발생시켜
제어권을 A에게로 넘겨준다. 역시 이 시점에도 마찬가지로 B자체가 task_struct이니 여기에 존재하는
thread_struct 구조체의 현재 레지스터 정보를 저장한다.
그리고 A로 돌아왔으니 이제 앞서서 thread_struct에 저장했던 레지스터 정보를 다시 빼온다.
그러면 레지스터 정보가 복원이 될 것이다.
복원이 되면서 num1 = 10 이었던 부분이 3으로 복원될 것이다.
이제 num2=7;을 수행하고 num3=num1+num2;를 수행하면 우리가 실제로 원했던 결과인 10을 얻을수 있을 것이다.

그렇다면 Context Switching은 무엇이냐
지금 위에다가 적어놓은 전반적인 과정이 바로 Context Switching을 의미한다.



2. Run Queue(Ready Queue)(런큐)
Run Queue란 CPU마다 1개씩 존재한다.
이 녀석은 실제로 동작하고 있거나 앞으로 동작하려고 하는 프로세스들이 올라와 있는 장소다.
프로세스이니 여기에 올라오는 정보는 당연히 task_struct이다.
(Linux Kernel의 핵심 구조체는 그래서 task_struct이다.
운영체제의 핵심적인 5대 요소에 속하는 파일 시스템, 메모리, 디바이스 드라이버, 네트워크, 프로세스가
모두 이 task_struct 구조체에 들어있다.)

어찌되었던 여기서는 실제 구동하는 프로세스들 혹은 구동할 준비가 된 프로세스들이 올라와있다.
혹시 구동을 하다가 앞서서 보았던 Time Slice라는 것이 만료가 된다면 Wait Queue로 빠져서 대기를 하고
대기 하고 있던 다른 프로세스(task_struct)가 이 Run Queue에 올라와서 구동을 시작하게 된다.

즉, Context Switching을 할 때 레지스터 정보뿐만 아니라 Run Queue와 Wait Queue모두에 task_struct를
옮겨주는 작업 또한 해줘야 한다.
(물론 이런 것들은 Kernel에서 알아서 해준다.
그렇지만 나만의 운영체제 및 RTOS를 구현하겠다면 직접 구현해야 한다)

추가적으로 System Programming에서 배우는 여러 가지 개념들을
잘 이해하고 파악해서 직접 프로그래밍 하기 위해서도 알아야 한다.
잘 모르면 코더, 잘 알면 개발자가 되는 거랄까?



3. Wait Queue(대기큐)
Wait Queue는 앞서서 1번과 2번에서도 보았겠지만
Context Switching을 수행하게 될 때 프로세스들이 들어가서 대기타고 있던 곳이다.
쉽게 생각하면 Run Queue는 잘 나가고 있는 것이고
Wait Queue는 유배를 갔다고 생각하면 된다.
사극을 보면 이렇게 유배 갔다가 칼을 갈아서 다시 Run Queue로 오는 것 처럼??



4. Scheduling(스케쥴링)
스케쥴링은 앞서서 살펴 보았던 1번과 2번 3번 모두의 개념이 필요하다.
기본적으로 이 3가지를 알고 있다고 전제를 깔아놓고 설명을 하겠다.
혹시 기억이 나지 않는다면 스크롤을 올려서 1,2,3번을 보자

앞서서 프로세스 A와 프로세스 B가 있었다.
이 녀석들의 스케쥴링에 대해서 생각해보도록 하자

아까는 프로세스 자체에 우선 순위를 넣어두지 않았는데
이젠 프로세스가 우선순위를 가지게 된다.
중요한 것은 우선순위가 생길경우 우선순위 숫자가 낮은 녀석이 Time Slice를 많이 받게된다.
(즉, 숫자가 낮으면 우선순위가 높고, 숫자가 크면 우선순위가 낮다)

커널 쪽에 들어갈 경우, 이것에 대해서 살펴볼 것이니
이 부분은 나중에 보도록 하자 - (코드가 한 1만줄 정도됨)

중요한 것은 우선 순위가 높은 녀석에게 Time Slice를 더 많이 준다는 것
즉, 우선순위가 높을수록 CPU를 더 많이 사용할 수 있다는 것이다.
그렇기 때문에 Kernel에서 프로세스를 CPU의 추상화라고 이야기한다.

이게 뭔 소리냐?
프로세스란? 우리가 C언어 및 여러 언어들을 가지고 만든 실행 파일이 실제 메모리에 load되어
구동하는 것을 의미한다. 그렇다면 결국 CPU에 존재하는 레지스터들을 사용하게 될 것이다.
또 CPU는 오직 한 순간에 하나의 작업만 수행할 수 있다.
결국 프로세스들 간에 CPU를 얻기 위해
경쟁을 하는 구도가 된다는 것이다.
즉, CPU를 얻어야만 동작하기에 프로세스를 CPU의 추상화라고 한다.

또 여기서 살펴봐야 할 것은 선점형(Primption)이 가능하냐 여부이다.
일반적인 OS의 경우 선점이 불가능하다.
그러나 Real-Time Scheduling(실시간 스케쥴링)을 지원할 경우
선점이 가능해진다.

선점이란 무엇일까?
Run Queue에 우선순위 10짜리가 동작하고 있다.
아직 Tile Slice가 다 지나가지 않았다.
그런데 우선순위 0짜리가 Run Queue에 들어갔다.
이렇게 되면 0이 "야! 너 나와" 하고 10짜리를 강제로 치우고 들어간다.
반면 선점을 지원하지 않는 경우, 그냥 좋은게 좋은거다 하고
Time Slice를 모두 만료하거나 동작이 종료되기 직전까지 우선순위 0 짜리도 대기를 하고 있어야 한다.
(차이가 있다면 선점이 가능하냐 여부이고 Time Slice를 많이 할당받는 것에 변함이 없다)

이것은 임베디드 분야에서 굉장히 중요한 부분인데
실제 군용 시스템들은 센서를 수십개 ~ 수백개 정도 쓴다.
센서 뿐만 아니라 엑츄에이터 등의 구동부분과
전기적인 제어를 수행하기 위한 변환 장치들등
엔진 제어등 여러부분이 존재하는데
쉬운예를 하나 들어보자

전투기가 있다고 가정해보자
일단 일반인들도 최소한으로 생각해볼 수 있는 기능은 아래와 같다.

1)레이더
2)미사일
3)통신
4)공기역학계산

여기서 제일 중요한 것은 우선 4번이다.
왜냐하면 애초에 공기역학이 계산이 안되면 기체 자체가 뜰수도 없고 설령 뜬다 하더라도
안정성이 형편없기 때문이다.

또다른 예로 인공위성을 생각해보자!
핵심 기능은 아래와 같다.

1)궤도계산(라그랑주 역학)
2)통신

여기서도 핵심은 궤도 계산이다.
이유는 계산을 못할 경우 주변ㅇ늬 물체들이 잡아당기는 만유인력에 의해서 우주의 미아가 되거나
지구에 꼬라박거나 둘 중 하나의 운명에 처하게 될 것이기 때문이다.
(실제로 미국의 화성 탐사선이 이 우선순위 문제로 미아가 된다.)

위와 같은 개념을 잡아놓은 상태에서 인공위성 케이스를 보도록 하자
실시간 스케쥴링과 일반 스케쥴링의 핵심적인 차이점을 볼 것이다.
인공위성이 궤도 계산이 제일 중요한데
이것의 동작이 일반 스케쥴링 방식이라고 생각해보자!
갑자기 통신 하느라고 궤도 계산을 실시간 스케쥴링 방식에 비해 소홀히 하게 될 것이다.
그러면 결국 위에 적은 지구에 꼬라박거나 궤도를 이탈하여 우주의 미아가 되는 현상을 겪게 될 것이다.
왜냐하면 지금 당장 궤도를 계산해야 하는데 통신하고 있기 때문이다.

좀더 나아가서 semaphore를 포함한 우선순위 문제도 있는데
실제로 화성 탐사선이 실종된 핵심 원인은 이 Semaphore에 의한 우선순위 문제이다.
이것을 해결하는 방식은 시어링이라는 방식이 있는데 향 후 커널쪽에서 코드를 살펴보면서
좀더 디테일하게 살펴보도록 하겠다.
우선은 실시간 스케쥴링과 일반 스케쥴링의 차이에 대해서 파악하면 됨


5. Multi-Tasking(멀티태스킹) - 코택용
동시다발적으로 굉장히 많은 작업을 하는 것을 일컫는 이야기다.(컴퓨터용어)

우선 Context Switching에 기반하여 여러개의 프로세스들을 아주 빠른 속도로 구동함으로써 이것이 가능해진다.
운동 선수가 0.3초를 감지할 수 있다고 한다.
일반인들은 0.4초정도를 감지한다고 한다.
그렇다면 컴퓨터가 인간이 감지할 수 있는 시간보다 더 짧은 시간 안에 모든 작업을 처리한다면
우리는 이 녀석들이 끊기고 있는지 느끼지 못할것이다.
(즉, 착시 현상을 주고 있는 것이다.)

실질적으로 A프로세스 0.001초, B프로세스 0.001초씩 동작한다면
50개가 돌아가도 총 0.05초로 인간은 느끼지도 못할 속도가 된다.
잘 생각해보면 현재 시중에 나와있는 CPU의 구동 클록은 GHz단위다.
즉, 10^9(10의9승) 단위인데 2GHz ~ 3GHz로 나온다.
이 뜻은 주파수가 3 x 10^9임을 의미한다.
즉 30 0000 0000(1초에 30억번 진동한다는 뜻)
이뜻은 1초에 연산할 수 있는 명령어가 30억개라는 뜻
0.1초면 3억개를 연산할 수 있고
0.01초면 3천만개, 0.001초면 3백만개임을 의미한다.
우리가 몇 줄 만든 코드는 어셈블리어로 보아도 몇백줄이 살짝 넘는다.
즉, 일반적인 프로세스에 0.001초도 과하다는 것을 알수 있다.
왜냐하면 0.001초에 3백만개의 연산을 수행할 수 있기 때문이다.

이렇게 아주 짧은 시간에 여러개의 프로세스들을 구동하면서 우리에게 모든 것이 동시에 돌아가는 것과 같은 착시 현상을 안겨주는 것이 바로 Multi-Tasking이다.
micro cos
free rtos
GPL라이센스가 붙은것 프리소프트웨어는 정책이 바뀌면 돈을 낼수도있다.
오픈소스는 코드만 공개하면 됨
스마트폰 커널은 리눅스 위에 안드로이드
게임은 모두 C나 C++

man readdir
/dirent
자마린
/////////////////////////end용어정리


sudo apt-get install ddd

apt-get은 로컬/인터넷에서 찾아서 다운로드후 설치
wget은 zip 파일이 웹에 있으면 wget으로 다운로드


헤더파일은 컴파일 시간에만 영향 런타임에는 영향x
















